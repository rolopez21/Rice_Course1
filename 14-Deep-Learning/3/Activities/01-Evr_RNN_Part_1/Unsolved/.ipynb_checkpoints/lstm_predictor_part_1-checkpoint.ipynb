{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this activity, we will prepare the training and testing data for the LSTM model.\n",
    "\n",
    "We will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the `X` and `y` values\n",
    "4. Reshape the `X_train` and `X_test` data for the model.\n",
    "\n",
    "**Note:** The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "In this activity, we will use closing prices from different stocks to make predictions of future closing prices based on the temporal data of each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stocks data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Features `X` and Target `y` Data\n",
    "\n",
    "The first step towards preparing the data is to create the input features vectors `X` and the target vector `y`. We will use the `window_data()` function to create these vectors.\n",
    "\n",
    "This function chunks the data up with a rolling window of _X<sub>t</sub> - window_ to predict _X<sub>t</sub>_.\n",
    "\n",
    "The function returns two `numpy` arrays:\n",
    "\n",
    "* `X`: The input features vectors.\n",
    "\n",
    "* `y`: The target vector.\n",
    "\n",
    "The function has the following parameters:\n",
    "\n",
    "* `df`: The original DataFrame with the time series data.\n",
    "\n",
    "* `window`: The window size in days of previous closing prices that will be used for the prediction.\n",
    "\n",
    "* `feature_col_number`: The column number from the original DataFrame where the features are located.\n",
    "\n",
    "* `target_col_number`: The column number from the original DataFrame where the target is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forthcoming activities, we will predict closing prices using a `5` days windows of previous _T-Bonds_ closing prices, so that, we will create the `X` and `y` vectors by calling the `window_data` function and defining a window size of `5` and setting the features and target column numbers to `2` (this is the column with the _T-Bonds_ closing prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 2\n",
    "target_column = 2\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Between Training and Testing Sets\n",
    "\n",
    "To avoid the dataset being randomized, we will manually split the data using array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data with `MinMaxScaler`\n",
    "\n",
    "Once the training and test datasets are created, we need to scale the data before training the LSTM model. We will use the `MinMaxScaler` from `sklearn` to scale all values between `0` and `1`.\n",
    "\n",
    "Note that we scale both features and target sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Features Data for the LSTM Model\n",
    "\n",
    "The LSTM API from Keras needs to receive the features data as a _vertical vector_, so that we need to reshape the `X` data in the form `reshape((X_train.shape[0], X_train.shape[1], 1))`.\n",
    "\n",
    "Both sets, training, and testing are reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
