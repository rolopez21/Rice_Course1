{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this activity, we will prepare the training and testing data for the LSTM model.\n",
    "\n",
    "We will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the `X` and `y` values\n",
    "4. Reshape the `X_train` and `X_test` data for the model.\n",
    "\n",
    "**Note:** The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "In this activity, we will use closing prices from different stocks to make predictions of future closing prices based on the temporal data of each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIX</th>\n",
       "      <th>Gold</th>\n",
       "      <th>T-Bonds</th>\n",
       "      <th>Junk Bonds</th>\n",
       "      <th>Oil</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2014-10-20</td>\n",
       "      <td>97500.0</td>\n",
       "      <td>119.80</td>\n",
       "      <td>29.18</td>\n",
       "      <td>121.08</td>\n",
       "      <td>33.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-10-21</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>120.02</td>\n",
       "      <td>29.14</td>\n",
       "      <td>121.59</td>\n",
       "      <td>34.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-10-22</td>\n",
       "      <td>95250.0</td>\n",
       "      <td>119.34</td>\n",
       "      <td>29.01</td>\n",
       "      <td>120.75</td>\n",
       "      <td>33.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-10-23</td>\n",
       "      <td>84750.0</td>\n",
       "      <td>118.52</td>\n",
       "      <td>28.96</td>\n",
       "      <td>120.84</td>\n",
       "      <td>34.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>82750.0</td>\n",
       "      <td>118.35</td>\n",
       "      <td>28.96</td>\n",
       "      <td>121.32</td>\n",
       "      <td>34.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                VIX    Gold  T-Bonds  Junk Bonds    Oil\n",
       "date                                                   \n",
       "2014-10-20  97500.0  119.80    29.18      121.08  33.78\n",
       "2014-10-21  83000.0  120.02    29.14      121.59  34.17\n",
       "2014-10-22  95250.0  119.34    29.01      120.75  33.53\n",
       "2014-10-23  84750.0  118.52    28.96      120.84  34.37\n",
       "2014-10-24  82750.0  118.35    28.96      121.32  34.17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the stocks data\n",
    "df = pd.read_csv(\n",
    "    Path(\"../Resources/stock_data.csv\"),\n",
    "    index_col=\"date\",\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates=True,\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Features `X` and Target `y` Data\n",
    "\n",
    "The first step towards preparing the data is to create the input features vectors `X` and the target vector `y`. We will use the `window_data()` function to create these vectors.\n",
    "\n",
    "This function chunks the data up with a rolling window of _X<sub>t</sub> - window_ to predict _X<sub>t</sub>_.\n",
    "\n",
    "The function returns two `numpy` arrays:\n",
    "\n",
    "* `X`: The input features vectors.\n",
    "\n",
    "* `y`: The target vector.\n",
    "\n",
    "The function has the following parameters:\n",
    "\n",
    "* `df`: The original DataFrame with the time series data.\n",
    "\n",
    "* `window`: The window size in days of previous closing prices that will be used for the prediction.\n",
    "\n",
    "* `feature_col_number`: The column number from the original DataFrame where the features are located.\n",
    "\n",
    "* `target_col_number`: The column number from the original DataFrame where the target is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forthcoming activities, we will predict closing prices using a `5` days windows of previous _T-Bonds_ closing prices, so that, we will create the `X` and `y` vectors by calling the `window_data` function and defining a window size of `5` and setting the features and target column numbers to `2` (this is the column with the _T-Bonds_ closing prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[29.18 29.14 29.01 28.96 28.96]\n",
      " [29.14 29.01 28.96 28.96 29.06]\n",
      " [29.01 28.96 28.96 29.06 29.1 ]\n",
      " [28.96 28.96 29.06 29.1  28.88]\n",
      " [28.96 29.06 29.1  28.88 28.82]] \n",
      "\n",
      "y sample values:\n",
      "[[29.06]\n",
      " [29.1 ]\n",
      " [28.88]\n",
      " [28.82]\n",
      " [28.59]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 2\n",
    "target_column = 2\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Between Training and Testing Sets\n",
    "\n",
    "To avoid the dataset being randomized, we will manually split the data using array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split - 1]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split - 1]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data with `MinMaxScaler`\n",
    "\n",
    "Once the training and test datasets are created, we need to scale the data before training the LSTM model. We will use the `MinMaxScaler` from `sklearn` to scale all values between `0` and `1`.\n",
    "\n",
    "Note that we scale both features and target sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Features Data for the LSTM Model\n",
    "\n",
    "The LSTM API from Keras needs to receive the features data as a _vertical vector_, so that we need to reshape the `X` data in the form `reshape((X_train.shape[0], X_train.shape[1], 1))`.\n",
    "\n",
    "Both sets, training, and testing are reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.8973747 ]\n",
      "  [0.88782816]\n",
      "  [0.85680191]\n",
      "  [0.84486874]\n",
      "  [0.84486874]]\n",
      "\n",
      " [[0.88782816]\n",
      "  [0.85680191]\n",
      "  [0.84486874]\n",
      "  [0.84486874]\n",
      "  [0.86873508]]\n",
      "\n",
      " [[0.85680191]\n",
      "  [0.84486874]\n",
      "  [0.84486874]\n",
      "  [0.86873508]\n",
      "  [0.87828162]]\n",
      "\n",
      " [[0.84486874]\n",
      "  [0.84486874]\n",
      "  [0.86873508]\n",
      "  [0.87828162]\n",
      "  [0.82577566]]\n",
      "\n",
      " [[0.84486874]\n",
      "  [0.86873508]\n",
      "  [0.87828162]\n",
      "  [0.82577566]\n",
      "  [0.81145585]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.96897375]\n",
      "  [0.97136038]\n",
      "  [0.96181384]\n",
      "  [0.93078759]\n",
      "  [0.87828162]]\n",
      "\n",
      " [[0.97136038]\n",
      "  [0.96181384]\n",
      "  [0.93078759]\n",
      "  [0.87828162]\n",
      "  [0.82100239]]\n",
      "\n",
      " [[0.96181384]\n",
      "  [0.93078759]\n",
      "  [0.87828162]\n",
      "  [0.82100239]\n",
      "  [0.81861575]]\n",
      "\n",
      " [[0.93078759]\n",
      "  [0.87828162]\n",
      "  [0.82100239]\n",
      "  [0.81861575]\n",
      "  [0.78042959]]\n",
      "\n",
      " [[0.87828162]\n",
      "  [0.82100239]\n",
      "  [0.81861575]\n",
      "  [0.78042959]\n",
      "  [0.78281623]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, we will design a custom LSTM RNN in Keras and fit (train) it using the training data we defined.\n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Define the model architecture in Keras.\n",
    "\n",
    "2. Compile the model.\n",
    "\n",
    "3. Fit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras Modules\n",
    "\n",
    "To build an LSTM RNN model in Keras, we will use the `Sequential` model as we did before; however, we will have two new types of layers:\n",
    "\n",
    "* `LSTM`: It's used to add an LSTM layer to the model.\n",
    "\n",
    "* `Dropout`: Dropout is a regularization technique for reducing overfitting in neural networks. This type of layer applies the dropout technique to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LSTM RNN Model Structure\n",
    "\n",
    "To create an LSTM RNN model, we will add `LSTM` layers. The `return_sequences` parameter needs to set to `True` every time we add a new `LSTM` layer, excluding the final layer. The `input_shape` is the number of time steps and the number of indicators\n",
    "\n",
    "After each `LSTM` layer, we add a `Dropout` layer to prevent overfitting. The parameter passed to the `Dropout` layer is the fraction of nodes that will be drop on each epoch, for this demo, we will use a dropout value of `0.2`, it means that on each epoch we will randomly drop `20%` of the units.\n",
    "\n",
    "The number of units in each `LSTM` layers, is equal to the size of the time window, in this demo, we are taking five previous `T-Bons` closing price to predict the next closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 5\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units = number_units,\n",
    "    return_sequences = True,\n",
    "    input_shape = (X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model.add(LSTM(\n",
    "    units = number_units,\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(\n",
    "    units = number_units,\n",
    "    return_sequences=False\n",
    "))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the LSTM RNN Model\n",
    "\n",
    "We will compile the model, using the `adam` optimizer, as loss function, we will use `mean_square_error` since the value we want to predict is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss=\"mean_squared_error\" #Regression\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "140/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 5)              140       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 5)              220       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 220       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 586\n",
      "Trainable params: 586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Once the model is defined, we train (fit) the model using `10` epochs. Since we are working with time-series data, it's important to set `shuffle=False` since it's necessary to keep the sequential order of the data.\n",
    "\n",
    "We can experiment with the `batch_size` parameter; however, smaller batch size is recommended; in this demo, we will use a `batch_size=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 876 samples\n",
      "Epoch 1/10\n",
      "876/876 [==============================] - 15s 17ms/sample - loss: 0.0438\n",
      "Epoch 2/10\n",
      "876/876 [==============================] - 10s 11ms/sample - loss: 0.0225\n",
      "Epoch 3/10\n",
      "876/876 [==============================] - 10s 11ms/sample - loss: 0.0203\n",
      "Epoch 4/10\n",
      "876/876 [==============================] - 10s 11ms/sample - loss: 0.0194\n",
      "Epoch 5/10\n",
      "876/876 [==============================] - 10s 12ms/sample - loss: 0.0163\n",
      "Epoch 6/10\n",
      "876/876 [==============================] - 12s 14ms/sample - loss: 0.0151\n",
      "Epoch 7/10\n",
      "876/876 [==============================] - 15s 17ms/sample - loss: 0.0121\n",
      "Epoch 8/10\n",
      "876/876 [==============================] - 11s 12ms/sample - loss: 0.0115\n",
      "Epoch 9/10\n",
      "876/876 [==============================] - 11s 12ms/sample - loss: 0.0106\n",
      "Epoch 10/10\n",
      "876/876 [==============================] - 11s 13ms/sample - loss: 0.0115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3f0d39e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
