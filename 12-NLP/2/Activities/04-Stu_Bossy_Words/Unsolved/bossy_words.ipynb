{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Who are the Bossy Words?\n","\n"," On this activity you will use TF-IDF to find the most relevant words on news articles that talk about money in the [Reuters Corpus](https://www.nltk.org/book/ch02.html#reuters-corpus) bundled in `NLTK`. Once you find the most relevant words, you should create a word cloud."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# initial imports\nimport nltk\nfrom nltk.corpus import reuters\nimport numpy as np\nimport pandas as pd\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nplt.style.use(\"seaborn-whitegrid\")\nmpl.rcParams[\"figure.figsize\"] = [20.0, 10.0]\n"},{"cell_type":"markdown","metadata":{},"source":[" ## Loading the Reuters Corpus\n","\n"," The first step is to load the Reuters Corpus."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Download/update the Reuters dataset\nnltk.download(\"reuters\")\n"},{"cell_type":"markdown","metadata":{},"source":[" ## Getting the News About Money\n","\n"," You will analyze only news that talk about _money_. There are two categories on the Reuters Corpus that talk about money: `money-fx` and `money-supply`. In this section, you will filter the news by these categories.\n","\n"," Take a look into the [Reuters Corpus documentation](https://www.nltk.org/book/ch02.html#reuters-corpus) and check how you can retrieve the categories of a document using the `reuters.categories()` method; write some lines of code to retrieve all the news articles that are under the `money-fx` or the `money-supply` categories.\n","\n"," **Hint:**\n"," You can use a comprehension list or a for-loop to accomplish this task."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Getting all documents ids under the money-fx and money-suppy categories\ncategories = [\"money-fx\", \"money-supply\"]\nall_docs_id = reuters.fileids()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Creating the working corpus containing the text from all the news articles about money\n\n# Printing a sample article\n"},{"cell_type":"markdown","metadata":{},"source":[" ## Calculating the TF-IDF Weights\n","\n"," Calculate the TF-IDF weight for each word on the working corpus using the `TfidfVectorizer()` class. Remember to include the `stop_words='english'` parameter."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Calculating TF-IDF for the working corpus.\n\n"},{"cell_type":"markdown","metadata":{},"source":[" Create a DataFrame representation of the TF-IDF weights of each term in the working corpus. Use the `sum(axis=0)` method to calculate a measure similar to the term frequency based on the TF-IDF weight, this value will be used to rank the terms for the word cloud creation."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Creating a DataFrame Representation of the TF-IDF results\n\n# Order the DataFrame by word frequency in descendent order\n\n# Print the top 10 words\nmoney_news_df.head(10)\n"},{"cell_type":"markdown","metadata":{},"source":[" ## Retrieving the Top Words\n","\n"," In order to create the word cloud you should get the top words, in this case we will use a thumb rule that has been empirically tested by some NLP experts that states that words with a frequency between 10 and 30 might be the most relevant in a corpus.\n","\n"," Following this rule, create a new DataFrame containing only those words with the mentioned frequency."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Top words will be those with an frequency between 10 ans 30 (thumb rule)\n\n\ntop_words.head(10)\n"},{"cell_type":"markdown","metadata":{},"source":[" ## Creating Word Cloud\n","\n"," Now you have all the pieces needed to create a word cloud based on TF-IDF weights, so use the `WordCloud` library to create it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Create a string list of terms to generate the word cloud\nterms_list = str(top_words[\"Word\"].tolist())\n\n# Create the word cloud\n\n"},{"cell_type":"markdown","metadata":{},"source":[" ## Challenge: Looking for Documents that Contains Top Words\n","\n"," Finally you might find interesting to search those articles that contain the most relevant words. Create a function called `retrieve_docs(terms)` that receive a list of terms as parameter and extract from the working corpus all those news articles that contains the search terms. On this function you should use the `reuters.words()` method to retrieve the tokenized version of each article as can be seen on the [Reuters Corpus documentation](https://www.nltk.org/book/ch02.html#reuters-corpus).\n","\n"," **Hint:** To find any occurrence of the search terms you might find quite useful [this post on StackOverflow](https://stackoverflow.com/a/25102099/4325668), also you should lower case all the words to ease your terms search."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def retrieve_docs(terms):\n\n"},{"cell_type":"markdown","metadata":{},"source":[" ### Question 1: How many articles talk about Yen?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"len(retrieve_docs([\"yen\"]))\n"},{"cell_type":"markdown","metadata":{},"source":"### Question 2: How many articles talk about Japan or Banks?"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"len(retrieve_docs([\"japan\", \"banks\"]))\n"},{"cell_type":"markdown","metadata":{},"source":[" ### Question 3: How many articles talk about England or Dealers?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"len(retrieve_docs([\"england\", \"dealers\"]))\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}