{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Wine Quality Predictor\n",
    "\n",
    "This notebook shows how to build a deep learning model to predict the quality score of different wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "data = Path(\"../Resources/winequality.csv\")\n",
    "df = pd.read_csv(data, delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>0.423333</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>2.577778</td>\n",
       "      <td>0.068444</td>\n",
       "      <td>13.277778</td>\n",
       "      <td>33.444444</td>\n",
       "      <td>0.995212</td>\n",
       "      <td>3.267222</td>\n",
       "      <td>0.767778</td>\n",
       "      <td>12.094444</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.119656</td>\n",
       "      <td>0.144914</td>\n",
       "      <td>0.199526</td>\n",
       "      <td>1.295038</td>\n",
       "      <td>0.011678</td>\n",
       "      <td>11.155613</td>\n",
       "      <td>25.433240</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.200640</td>\n",
       "      <td>0.115379</td>\n",
       "      <td>1.224011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>2.880000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>3.162500</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>11.325000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0.994940</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>10.225000</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count      18.000000         18.000000    18.000000       18.000000   \n",
       "mean        8.566667          0.423333     0.391111        2.577778   \n",
       "std         2.119656          0.144914     0.199526        1.295038   \n",
       "min         5.000000          0.260000     0.030000        1.400000   \n",
       "25%         7.250000          0.335000     0.302500        1.800000   \n",
       "50%         8.250000          0.370000     0.420000        2.100000   \n",
       "75%        10.225000          0.472500     0.530000        2.600000   \n",
       "max        12.600000          0.850000     0.720000        6.400000   \n",
       "\n",
       "       chlorides  free sulfur dioxide  total sulfur dioxide    density  \\\n",
       "count  18.000000            18.000000             18.000000  18.000000   \n",
       "mean    0.068444            13.277778             33.444444   0.995212   \n",
       "std     0.011678            11.155613             25.433240   0.002378   \n",
       "min     0.044000             3.000000             12.000000   0.990800   \n",
       "25%     0.062000             6.000000             16.000000   0.994175   \n",
       "50%     0.070500             7.500000             21.500000   0.994940   \n",
       "75%     0.075500            16.500000             43.000000   0.997200   \n",
       "max     0.086000            42.000000             88.000000   0.998800   \n",
       "\n",
       "              pH  sulphates    alcohol  quality  \n",
       "count  18.000000  18.000000  18.000000     18.0  \n",
       "mean    3.267222   0.767778  12.094444      8.0  \n",
       "std     0.200640   0.115379   1.224011      0.0  \n",
       "min     2.880000   0.630000   9.800000      8.0  \n",
       "25%     3.162500   0.690000  11.325000      8.0  \n",
       "50%     3.230000   0.740000  12.150000      8.0  \n",
       "75%     3.350000   0.820000  12.875000      8.0  \n",
       "max     3.720000   1.100000  14.000000      8.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"quality\"]==8].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:11].values\n",
    "y = df[\"quality\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - shallow neural net\n",
    "number_hidden_nodes = 8\n",
    "number_input_features = 11\n",
    "\n",
    "\n",
    "nn = Sequential()\n",
    "# Hidden layer\n",
    "nn.add(\n",
    "    Dense(units=number_hidden_nodes, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1119 samples, validate on 480 samples\n",
      "Epoch 1/200\n",
      "1119/1119 [==============================] - 1s 942us/sample - loss: 26.3436 - mse: 26.3436 - val_loss: 26.0644 - val_mse: 26.0644\n",
      "Epoch 2/200\n",
      "1119/1119 [==============================] - 0s 130us/sample - loss: 23.2531 - mse: 23.2531 - val_loss: 23.0067 - val_mse: 23.0067\n",
      "Epoch 3/200\n",
      "1119/1119 [==============================] - 0s 156us/sample - loss: 20.3586 - mse: 20.3586 - val_loss: 20.1163 - val_mse: 20.1163\n",
      "Epoch 4/200\n",
      "1119/1119 [==============================] - 0s 212us/sample - loss: 17.6292 - mse: 17.6292 - val_loss: 17.3285 - val_mse: 17.3285\n",
      "Epoch 5/200\n",
      "1119/1119 [==============================] - 1s 472us/sample - loss: 15.1172 - mse: 15.1172 - val_loss: 14.7217 - val_mse: 14.7217\n",
      "Epoch 6/200\n",
      "1119/1119 [==============================] - 0s 338us/sample - loss: 12.8305 - mse: 12.8305 - val_loss: 12.2963 - val_mse: 12.2963\n",
      "Epoch 7/200\n",
      "1119/1119 [==============================] - 0s 220us/sample - loss: 10.8084 - mse: 10.8084 - val_loss: 10.1974 - val_mse: 10.1974\n",
      "Epoch 8/200\n",
      "1119/1119 [==============================] - 0s 143us/sample - loss: 9.0738 - mse: 9.0738 - val_loss: 8.3989 - val_mse: 8.3988\n",
      "Epoch 9/200\n",
      "1119/1119 [==============================] - 0s 217us/sample - loss: 7.6552 - mse: 7.6552 - val_loss: 6.9321 - val_mse: 6.9321\n",
      "Epoch 10/200\n",
      "1119/1119 [==============================] - 0s 259us/sample - loss: 6.5207 - mse: 6.5207 - val_loss: 5.8066 - val_mse: 5.8066\n",
      "Epoch 11/200\n",
      "1119/1119 [==============================] - 0s 138us/sample - loss: 5.6347 - mse: 5.6347 - val_loss: 4.9640 - val_mse: 4.9640\n",
      "Epoch 12/200\n",
      "1119/1119 [==============================] - 0s 153us/sample - loss: 4.9397 - mse: 4.9397 - val_loss: 4.3424 - val_mse: 4.3424\n",
      "Epoch 13/200\n",
      "1119/1119 [==============================] - 0s 148us/sample - loss: 4.4084 - mse: 4.4084 - val_loss: 3.8680 - val_mse: 3.8680\n",
      "Epoch 14/200\n",
      "1119/1119 [==============================] - 0s 174us/sample - loss: 3.9799 - mse: 3.9799 - val_loss: 3.5116 - val_mse: 3.5116\n",
      "Epoch 15/200\n",
      "1119/1119 [==============================] - 0s 143us/sample - loss: 3.6423 - mse: 3.6423 - val_loss: 3.2213 - val_mse: 3.2213\n",
      "Epoch 16/200\n",
      "1119/1119 [==============================] - 0s 118us/sample - loss: 3.3614 - mse: 3.3614 - val_loss: 2.9869 - val_mse: 2.9869\n",
      "Epoch 17/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 3.1290 - mse: 3.1290 - val_loss: 2.7934 - val_mse: 2.7934\n",
      "Epoch 18/200\n",
      "1119/1119 [==============================] - 0s 131us/sample - loss: 2.9341 - mse: 2.9341 - val_loss: 2.6175 - val_mse: 2.6175\n",
      "Epoch 19/200\n",
      "1119/1119 [==============================] - 0s 145us/sample - loss: 2.7616 - mse: 2.7616 - val_loss: 2.4588 - val_mse: 2.4588\n",
      "Epoch 20/200\n",
      "1119/1119 [==============================] - 0s 186us/sample - loss: 2.6173 - mse: 2.6173 - val_loss: 2.3406 - val_mse: 2.3406\n",
      "Epoch 21/200\n",
      "1119/1119 [==============================] - 0s 120us/sample - loss: 2.4884 - mse: 2.4884 - val_loss: 2.2288 - val_mse: 2.2288\n",
      "Epoch 22/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 2.3781 - mse: 2.3781 - val_loss: 2.1367 - val_mse: 2.1367\n",
      "Epoch 23/200\n",
      "1119/1119 [==============================] - 0s 126us/sample - loss: 2.2813 - mse: 2.2813 - val_loss: 2.0513 - val_mse: 2.0513\n",
      "Epoch 24/200\n",
      "1119/1119 [==============================] - 0s 161us/sample - loss: 2.1927 - mse: 2.1927 - val_loss: 1.9821 - val_mse: 1.9821\n",
      "Epoch 25/200\n",
      "1119/1119 [==============================] - 0s 146us/sample - loss: 2.1155 - mse: 2.1155 - val_loss: 1.9269 - val_mse: 1.9269\n",
      "Epoch 26/200\n",
      "1119/1119 [==============================] - 0s 109us/sample - loss: 2.0424 - mse: 2.0424 - val_loss: 1.8652 - val_mse: 1.8652\n",
      "Epoch 27/200\n",
      "1119/1119 [==============================] - 0s 120us/sample - loss: 1.9774 - mse: 1.9774 - val_loss: 1.8171 - val_mse: 1.8171\n",
      "Epoch 28/200\n",
      "1119/1119 [==============================] - 0s 154us/sample - loss: 1.9181 - mse: 1.9181 - val_loss: 1.7683 - val_mse: 1.7683\n",
      "Epoch 29/200\n",
      "1119/1119 [==============================] - 0s 123us/sample - loss: 1.8620 - mse: 1.8620 - val_loss: 1.7222 - val_mse: 1.7222\n",
      "Epoch 30/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 1.8089 - mse: 1.8089 - val_loss: 1.6856 - val_mse: 1.6856\n",
      "Epoch 31/200\n",
      "1119/1119 [==============================] - 0s 106us/sample - loss: 1.7580 - mse: 1.7580 - val_loss: 1.6473 - val_mse: 1.6473\n",
      "Epoch 32/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 1.7088 - mse: 1.7088 - val_loss: 1.6127 - val_mse: 1.6127\n",
      "Epoch 33/200\n",
      "1119/1119 [==============================] - 0s 116us/sample - loss: 1.6648 - mse: 1.6648 - val_loss: 1.5795 - val_mse: 1.5795\n",
      "Epoch 34/200\n",
      "1119/1119 [==============================] - 0s 140us/sample - loss: 1.6195 - mse: 1.6195 - val_loss: 1.5520 - val_mse: 1.5520\n",
      "Epoch 35/200\n",
      "1119/1119 [==============================] - 0s 152us/sample - loss: 1.5780 - mse: 1.5780 - val_loss: 1.5235 - val_mse: 1.5235\n",
      "Epoch 36/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 1.5401 - mse: 1.5401 - val_loss: 1.4969 - val_mse: 1.4969\n",
      "Epoch 37/200\n",
      "1119/1119 [==============================] - 0s 120us/sample - loss: 1.5032 - mse: 1.5032 - val_loss: 1.4661 - val_mse: 1.4661\n",
      "Epoch 38/200\n",
      "1119/1119 [==============================] - 0s 120us/sample - loss: 1.4646 - mse: 1.4646 - val_loss: 1.4329 - val_mse: 1.4329\n",
      "Epoch 39/200\n",
      "1119/1119 [==============================] - 0s 139us/sample - loss: 1.4291 - mse: 1.4291 - val_loss: 1.4040 - val_mse: 1.4040\n",
      "Epoch 40/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 1.3948 - mse: 1.3948 - val_loss: 1.3778 - val_mse: 1.3778\n",
      "Epoch 41/200\n",
      "1119/1119 [==============================] - 0s 131us/sample - loss: 1.3612 - mse: 1.3612 - val_loss: 1.3598 - val_mse: 1.3598\n",
      "Epoch 42/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 1.3292 - mse: 1.3292 - val_loss: 1.3372 - val_mse: 1.3372\n",
      "Epoch 43/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 1.2984 - mse: 1.2984 - val_loss: 1.3166 - val_mse: 1.3166\n",
      "Epoch 44/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 1.2663 - mse: 1.2663 - val_loss: 1.2857 - val_mse: 1.2857\n",
      "Epoch 45/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 1.2393 - mse: 1.2393 - val_loss: 1.2766 - val_mse: 1.2766\n",
      "Epoch 46/200\n",
      "1119/1119 [==============================] - 0s 163us/sample - loss: 1.2074 - mse: 1.2074 - val_loss: 1.2407 - val_mse: 1.2407\n",
      "Epoch 47/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 1.1810 - mse: 1.1810 - val_loss: 1.2325 - val_mse: 1.2325\n",
      "Epoch 48/200\n",
      "1119/1119 [==============================] - 0s 95us/sample - loss: 1.1527 - mse: 1.1527 - val_loss: 1.2031 - val_mse: 1.2031\n",
      "Epoch 49/200\n",
      "1119/1119 [==============================] - 0s 139us/sample - loss: 1.1262 - mse: 1.1262 - val_loss: 1.1832 - val_mse: 1.1832\n",
      "Epoch 50/200\n",
      "1119/1119 [==============================] - 0s 98us/sample - loss: 1.0982 - mse: 1.0982 - val_loss: 1.1573 - val_mse: 1.1573\n",
      "Epoch 51/200\n",
      "1119/1119 [==============================] - 0s 118us/sample - loss: 1.0713 - mse: 1.0713 - val_loss: 1.1367 - val_mse: 1.1367\n",
      "Epoch 52/200\n",
      "1119/1119 [==============================] - 0s 140us/sample - loss: 1.0474 - mse: 1.0474 - val_loss: 1.1181 - val_mse: 1.1181\n",
      "Epoch 53/200\n",
      "1119/1119 [==============================] - 0s 112us/sample - loss: 1.0235 - mse: 1.0235 - val_loss: 1.0966 - val_mse: 1.0966\n",
      "Epoch 54/200\n",
      "1119/1119 [==============================] - 0s 134us/sample - loss: 0.9987 - mse: 0.9987 - val_loss: 1.0792 - val_mse: 1.0792\n",
      "Epoch 55/200\n",
      "1119/1119 [==============================] - 0s 188us/sample - loss: 0.9776 - mse: 0.9776 - val_loss: 1.0623 - val_mse: 1.0623\n",
      "Epoch 56/200\n",
      "1119/1119 [==============================] - 0s 159us/sample - loss: 0.9544 - mse: 0.9544 - val_loss: 1.0282 - val_mse: 1.0282\n",
      "Epoch 57/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.9299 - mse: 0.9299 - val_loss: 1.0148 - val_mse: 1.0148\n",
      "Epoch 58/200\n",
      "1119/1119 [==============================] - 0s 127us/sample - loss: 0.9098 - mse: 0.9098 - val_loss: 0.9983 - val_mse: 0.9983\n",
      "Epoch 59/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.8863 - mse: 0.8863 - val_loss: 0.9868 - val_mse: 0.9868\n",
      "Epoch 60/200\n",
      "1119/1119 [==============================] - 0s 131us/sample - loss: 0.8696 - mse: 0.8696 - val_loss: 0.9703 - val_mse: 0.9703\n",
      "Epoch 61/200\n",
      "1119/1119 [==============================] - 0s 171us/sample - loss: 0.8471 - mse: 0.8471 - val_loss: 0.9404 - val_mse: 0.9404\n",
      "Epoch 62/200\n",
      "1119/1119 [==============================] - 0s 116us/sample - loss: 0.8275 - mse: 0.8275 - val_loss: 0.9287 - val_mse: 0.9287\n",
      "Epoch 63/200\n",
      "1119/1119 [==============================] - 0s 116us/sample - loss: 0.8073 - mse: 0.8073 - val_loss: 0.9067 - val_mse: 0.9067\n",
      "Epoch 64/200\n",
      "1119/1119 [==============================] - 0s 126us/sample - loss: 0.7887 - mse: 0.7887 - val_loss: 0.8999 - val_mse: 0.8999\n",
      "Epoch 65/200\n",
      "1119/1119 [==============================] - 0s 148us/sample - loss: 0.7709 - mse: 0.7709 - val_loss: 0.8809 - val_mse: 0.8809\n",
      "Epoch 66/200\n",
      "1119/1119 [==============================] - 0s 141us/sample - loss: 0.7558 - mse: 0.7558 - val_loss: 0.8718 - val_mse: 0.8718\n",
      "Epoch 67/200\n",
      "1119/1119 [==============================] - 0s 109us/sample - loss: 0.7382 - mse: 0.7382 - val_loss: 0.8490 - val_mse: 0.8490\n",
      "Epoch 68/200\n",
      "1119/1119 [==============================] - 0s 107us/sample - loss: 0.7249 - mse: 0.7249 - val_loss: 0.8404 - val_mse: 0.8404\n",
      "Epoch 69/200\n",
      "1119/1119 [==============================] - 0s 160us/sample - loss: 0.7113 - mse: 0.7113 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 70/200\n",
      "1119/1119 [==============================] - 0s 155us/sample - loss: 0.6981 - mse: 0.6981 - val_loss: 0.8117 - val_mse: 0.8117\n",
      "Epoch 71/200\n",
      "1119/1119 [==============================] - 0s 210us/sample - loss: 0.6843 - mse: 0.6843 - val_loss: 0.8021 - val_mse: 0.8021\n",
      "Epoch 72/200\n",
      "1119/1119 [==============================] - 0s 152us/sample - loss: 0.6710 - mse: 0.6710 - val_loss: 0.7858 - val_mse: 0.7858\n",
      "Epoch 73/200\n",
      "1119/1119 [==============================] - 0s 121us/sample - loss: 0.6587 - mse: 0.6587 - val_loss: 0.7866 - val_mse: 0.7866\n",
      "Epoch 74/200\n",
      "1119/1119 [==============================] - 0s 193us/sample - loss: 0.6468 - mse: 0.6468 - val_loss: 0.7685 - val_mse: 0.7685\n",
      "Epoch 75/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 0.6332 - mse: 0.6332 - val_loss: 0.7450 - val_mse: 0.7450\n",
      "Epoch 76/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 0.6234 - mse: 0.6234 - val_loss: 0.7340 - val_mse: 0.7340\n",
      "Epoch 77/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.6134 - mse: 0.6134 - val_loss: 0.7386 - val_mse: 0.7386\n",
      "Epoch 78/200\n",
      "1119/1119 [==============================] - 0s 151us/sample - loss: 0.6024 - mse: 0.6024 - val_loss: 0.7182 - val_mse: 0.7182\n",
      "Epoch 79/200\n",
      "1119/1119 [==============================] - 0s 137us/sample - loss: 0.5925 - mse: 0.5925 - val_loss: 0.7004 - val_mse: 0.7004\n",
      "Epoch 80/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.5844 - mse: 0.5844 - val_loss: 0.6908 - val_mse: 0.6908\n",
      "Epoch 81/200\n",
      "1119/1119 [==============================] - 0s 118us/sample - loss: 0.5754 - mse: 0.5754 - val_loss: 0.6882 - val_mse: 0.6882\n",
      "Epoch 82/200\n",
      "1119/1119 [==============================] - 0s 132us/sample - loss: 0.5674 - mse: 0.5674 - val_loss: 0.6712 - val_mse: 0.6712\n",
      "Epoch 83/200\n",
      "1119/1119 [==============================] - 0s 101us/sample - loss: 0.5572 - mse: 0.5572 - val_loss: 0.6668 - val_mse: 0.6668\n",
      "Epoch 84/200\n",
      "1119/1119 [==============================] - 0s 159us/sample - loss: 0.5479 - mse: 0.5479 - val_loss: 0.6562 - val_mse: 0.6562\n",
      "Epoch 85/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.5408 - mse: 0.5408 - val_loss: 0.6480 - val_mse: 0.6480\n",
      "Epoch 86/200\n",
      "1119/1119 [==============================] - 0s 104us/sample - loss: 0.5321 - mse: 0.5321 - val_loss: 0.6511 - val_mse: 0.6511\n",
      "Epoch 87/200\n",
      "1119/1119 [==============================] - 0s 157us/sample - loss: 0.5264 - mse: 0.5264 - val_loss: 0.6395 - val_mse: 0.6395\n",
      "Epoch 88/200\n",
      "1119/1119 [==============================] - 0s 122us/sample - loss: 0.5191 - mse: 0.5191 - val_loss: 0.6247 - val_mse: 0.6247\n",
      "Epoch 89/200\n",
      "1119/1119 [==============================] - 0s 95us/sample - loss: 0.5126 - mse: 0.5126 - val_loss: 0.6235 - val_mse: 0.6235\n",
      "Epoch 90/200\n",
      "1119/1119 [==============================] - 0s 144us/sample - loss: 0.5066 - mse: 0.5066 - val_loss: 0.6100 - val_mse: 0.6100\n",
      "Epoch 91/200\n",
      "1119/1119 [==============================] - 0s 130us/sample - loss: 0.5021 - mse: 0.5021 - val_loss: 0.6126 - val_mse: 0.6126\n",
      "Epoch 92/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 0.4985 - mse: 0.4985 - val_loss: 0.5967 - val_mse: 0.5967\n",
      "Epoch 93/200\n",
      "1119/1119 [==============================] - 0s 187us/sample - loss: 0.4904 - mse: 0.4904 - val_loss: 0.5971 - val_mse: 0.5971\n",
      "Epoch 94/200\n",
      "1119/1119 [==============================] - 0s 209us/sample - loss: 0.4857 - mse: 0.4857 - val_loss: 0.5914 - val_mse: 0.5914\n",
      "Epoch 95/200\n",
      "1119/1119 [==============================] - 0s 157us/sample - loss: 0.4830 - mse: 0.4830 - val_loss: 0.5866 - val_mse: 0.5866\n",
      "Epoch 96/200\n",
      "1119/1119 [==============================] - 0s 122us/sample - loss: 0.4784 - mse: 0.4784 - val_loss: 0.5833 - val_mse: 0.5833\n",
      "Epoch 97/200\n",
      "1119/1119 [==============================] - 0s 171us/sample - loss: 0.4749 - mse: 0.4749 - val_loss: 0.5830 - val_mse: 0.5830\n",
      "Epoch 98/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.4721 - mse: 0.4721 - val_loss: 0.5767 - val_mse: 0.5767\n",
      "Epoch 99/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 0.4679 - mse: 0.4679 - val_loss: 0.5723 - val_mse: 0.5723\n",
      "Epoch 100/200\n",
      "1119/1119 [==============================] - 0s 122us/sample - loss: 0.4653 - mse: 0.4653 - val_loss: 0.5639 - val_mse: 0.5639\n",
      "Epoch 101/200\n",
      "1119/1119 [==============================] - 0s 177us/sample - loss: 0.4603 - mse: 0.4603 - val_loss: 0.5650 - val_mse: 0.5650\n",
      "Epoch 102/200\n",
      "1119/1119 [==============================] - 0s 123us/sample - loss: 0.4574 - mse: 0.4574 - val_loss: 0.5583 - val_mse: 0.5583\n",
      "Epoch 103/200\n",
      "1119/1119 [==============================] - 0s 133us/sample - loss: 0.4545 - mse: 0.4545 - val_loss: 0.5557 - val_mse: 0.5557\n",
      "Epoch 104/200\n",
      "1119/1119 [==============================] - 0s 147us/sample - loss: 0.4507 - mse: 0.4507 - val_loss: 0.5515 - val_mse: 0.5515\n",
      "Epoch 105/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 0.4476 - mse: 0.4476 - val_loss: 0.5454 - val_mse: 0.5454\n",
      "Epoch 106/200\n",
      "1119/1119 [==============================] - 0s 112us/sample - loss: 0.4458 - mse: 0.4458 - val_loss: 0.5474 - val_mse: 0.5474\n",
      "Epoch 107/200\n",
      "1119/1119 [==============================] - 0s 146us/sample - loss: 0.4427 - mse: 0.4427 - val_loss: 0.5370 - val_mse: 0.5370\n",
      "Epoch 108/200\n",
      "1119/1119 [==============================] - 0s 142us/sample - loss: 0.4402 - mse: 0.4402 - val_loss: 0.5341 - val_mse: 0.5341\n",
      "Epoch 109/200\n",
      "1119/1119 [==============================] - 0s 151us/sample - loss: 0.4391 - mse: 0.4391 - val_loss: 0.5317 - val_mse: 0.5317\n",
      "Epoch 110/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.4353 - mse: 0.4353 - val_loss: 0.5287 - val_mse: 0.5287\n",
      "Epoch 111/200\n",
      "1119/1119 [==============================] - 0s 97us/sample - loss: 0.4330 - mse: 0.4330 - val_loss: 0.5246 - val_mse: 0.5246\n",
      "Epoch 112/200\n",
      "1119/1119 [==============================] - 0s 184us/sample - loss: 0.4308 - mse: 0.4308 - val_loss: 0.5210 - val_mse: 0.5210\n",
      "Epoch 113/200\n",
      "1119/1119 [==============================] - 0s 181us/sample - loss: 0.4289 - mse: 0.4289 - val_loss: 0.5150 - val_mse: 0.5150\n",
      "Epoch 114/200\n",
      "1119/1119 [==============================] - 0s 191us/sample - loss: 0.4262 - mse: 0.4262 - val_loss: 0.5137 - val_mse: 0.5137\n",
      "Epoch 115/200\n",
      "1119/1119 [==============================] - 0s 150us/sample - loss: 0.4250 - mse: 0.4250 - val_loss: 0.5149 - val_mse: 0.5149\n",
      "Epoch 116/200\n",
      "1119/1119 [==============================] - 0s 205us/sample - loss: 0.4222 - mse: 0.4222 - val_loss: 0.5124 - val_mse: 0.5124\n",
      "Epoch 117/200\n",
      "1119/1119 [==============================] - 0s 235us/sample - loss: 0.4208 - mse: 0.4208 - val_loss: 0.5048 - val_mse: 0.5048\n",
      "Epoch 118/200\n",
      "1119/1119 [==============================] - 0s 177us/sample - loss: 0.4189 - mse: 0.4189 - val_loss: 0.5009 - val_mse: 0.5009\n",
      "Epoch 119/200\n",
      "1119/1119 [==============================] - 0s 203us/sample - loss: 0.4176 - mse: 0.4176 - val_loss: 0.5057 - val_mse: 0.5057\n",
      "Epoch 120/200\n",
      "1119/1119 [==============================] - 0s 229us/sample - loss: 0.4170 - mse: 0.4170 - val_loss: 0.4994 - val_mse: 0.4994\n",
      "Epoch 121/200\n",
      "1119/1119 [==============================] - 0s 99us/sample - loss: 0.4152 - mse: 0.4152 - val_loss: 0.4984 - val_mse: 0.4984\n",
      "Epoch 122/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.4130 - mse: 0.4130 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 123/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.4115 - mse: 0.4115 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 124/200\n",
      "1119/1119 [==============================] - 0s 123us/sample - loss: 0.4106 - mse: 0.4106 - val_loss: 0.4956 - val_mse: 0.4956\n",
      "Epoch 125/200\n",
      "1119/1119 [==============================] - 0s 153us/sample - loss: 0.4090 - mse: 0.4090 - val_loss: 0.4936 - val_mse: 0.4936\n",
      "Epoch 126/200\n",
      "1119/1119 [==============================] - 0s 130us/sample - loss: 0.4087 - mse: 0.4087 - val_loss: 0.4912 - val_mse: 0.4912\n",
      "Epoch 127/200\n",
      "1119/1119 [==============================] - 0s 99us/sample - loss: 0.4066 - mse: 0.4066 - val_loss: 0.4901 - val_mse: 0.4901\n",
      "Epoch 128/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 0.4070 - mse: 0.4070 - val_loss: 0.4959 - val_mse: 0.4959\n",
      "Epoch 129/200\n",
      "1119/1119 [==============================] - 0s 100us/sample - loss: 0.4075 - mse: 0.4075 - val_loss: 0.4894 - val_mse: 0.4894\n",
      "Epoch 130/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 0.4057 - mse: 0.4057 - val_loss: 0.4872 - val_mse: 0.4872\n",
      "Epoch 131/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.4040 - mse: 0.4040 - val_loss: 0.4884 - val_mse: 0.4884\n",
      "Epoch 132/200\n",
      "1119/1119 [==============================] - 0s 118us/sample - loss: 0.4033 - mse: 0.4033 - val_loss: 0.4858 - val_mse: 0.4858\n",
      "Epoch 133/200\n",
      "1119/1119 [==============================] - 0s 128us/sample - loss: 0.4019 - mse: 0.4019 - val_loss: 0.4847 - val_mse: 0.4847\n",
      "Epoch 134/200\n",
      "1119/1119 [==============================] - 0s 165us/sample - loss: 0.4018 - mse: 0.4018 - val_loss: 0.4791 - val_mse: 0.4791\n",
      "Epoch 135/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 0.4006 - mse: 0.4006 - val_loss: 0.4833 - val_mse: 0.4833\n",
      "Epoch 136/200\n",
      "1119/1119 [==============================] - 0s 93us/sample - loss: 0.3996 - mse: 0.3996 - val_loss: 0.4830 - val_mse: 0.4830\n",
      "Epoch 137/200\n",
      "1119/1119 [==============================] - 0s 147us/sample - loss: 0.4002 - mse: 0.4002 - val_loss: 0.4794 - val_mse: 0.4794\n",
      "Epoch 138/200\n",
      "1119/1119 [==============================] - 0s 296us/sample - loss: 0.3988 - mse: 0.3988 - val_loss: 0.4817 - val_mse: 0.4817\n",
      "Epoch 139/200\n",
      "1119/1119 [==============================] - 0s 202us/sample - loss: 0.3970 - mse: 0.3970 - val_loss: 0.4775 - val_mse: 0.4775\n",
      "Epoch 140/200\n",
      "1119/1119 [==============================] - 0s 138us/sample - loss: 0.3973 - mse: 0.3973 - val_loss: 0.4706 - val_mse: 0.4706\n",
      "Epoch 141/200\n",
      "1119/1119 [==============================] - 0s 177us/sample - loss: 0.3946 - mse: 0.3946 - val_loss: 0.4808 - val_mse: 0.4808\n",
      "Epoch 142/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 0.3964 - mse: 0.3964 - val_loss: 0.4774 - val_mse: 0.4774\n",
      "Epoch 143/200\n",
      "1119/1119 [==============================] - 0s 152us/sample - loss: 0.3950 - mse: 0.3950 - val_loss: 0.4708 - val_mse: 0.4708\n",
      "Epoch 144/200\n",
      "1119/1119 [==============================] - 0s 115us/sample - loss: 0.3942 - mse: 0.3942 - val_loss: 0.4707 - val_mse: 0.4707\n",
      "Epoch 145/200\n",
      "1119/1119 [==============================] - 0s 127us/sample - loss: 0.3940 - mse: 0.3940 - val_loss: 0.4681 - val_mse: 0.4681\n",
      "Epoch 146/200\n",
      "1119/1119 [==============================] - 0s 152us/sample - loss: 0.3931 - mse: 0.3931 - val_loss: 0.4704 - val_mse: 0.4704\n",
      "Epoch 147/200\n",
      "1119/1119 [==============================] - 0s 127us/sample - loss: 0.3937 - mse: 0.3937 - val_loss: 0.4687 - val_mse: 0.4687\n",
      "Epoch 148/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3920 - mse: 0.3920 - val_loss: 0.4660 - val_mse: 0.4660\n",
      "Epoch 149/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.3912 - mse: 0.3912 - val_loss: 0.4713 - val_mse: 0.4713\n",
      "Epoch 150/200\n",
      "1119/1119 [==============================] - 0s 107us/sample - loss: 0.3931 - mse: 0.3931 - val_loss: 0.4589 - val_mse: 0.4589\n",
      "Epoch 151/200\n",
      "1119/1119 [==============================] - 0s 132us/sample - loss: 0.3921 - mse: 0.3921 - val_loss: 0.4646 - val_mse: 0.4646\n",
      "Epoch 152/200\n",
      "1119/1119 [==============================] - 0s 147us/sample - loss: 0.3901 - mse: 0.3901 - val_loss: 0.4696 - val_mse: 0.4696\n",
      "Epoch 153/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.3889 - mse: 0.3889 - val_loss: 0.4703 - val_mse: 0.4703\n",
      "Epoch 154/200\n",
      "1119/1119 [==============================] - 0s 155us/sample - loss: 0.3895 - mse: 0.3895 - val_loss: 0.4735 - val_mse: 0.4735\n",
      "Epoch 155/200\n",
      "1119/1119 [==============================] - 0s 112us/sample - loss: 0.3876 - mse: 0.3876 - val_loss: 0.4662 - val_mse: 0.4662\n",
      "Epoch 156/200\n",
      "1119/1119 [==============================] - 0s 107us/sample - loss: 0.3877 - mse: 0.3877 - val_loss: 0.4673 - val_mse: 0.4673\n",
      "Epoch 157/200\n",
      "1119/1119 [==============================] - 0s 127us/sample - loss: 0.3865 - mse: 0.3865 - val_loss: 0.4655 - val_mse: 0.4655\n",
      "Epoch 158/200\n",
      "1119/1119 [==============================] - 0s 134us/sample - loss: 0.3868 - mse: 0.3868 - val_loss: 0.4688 - val_mse: 0.4688\n",
      "Epoch 159/200\n",
      "1119/1119 [==============================] - 0s 116us/sample - loss: 0.3857 - mse: 0.3857 - val_loss: 0.4634 - val_mse: 0.4634\n",
      "Epoch 160/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 0.3881 - mse: 0.3881 - val_loss: 0.4683 - val_mse: 0.4683\n",
      "Epoch 161/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 0.3854 - mse: 0.3854 - val_loss: 0.4664 - val_mse: 0.4664\n",
      "Epoch 162/200\n",
      "1119/1119 [==============================] - 0s 141us/sample - loss: 0.3854 - mse: 0.3854 - val_loss: 0.4634 - val_mse: 0.4634\n",
      "Epoch 163/200\n",
      "1119/1119 [==============================] - 0s 103us/sample - loss: 0.3850 - mse: 0.3850 - val_loss: 0.4678 - val_mse: 0.4678\n",
      "Epoch 164/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3849 - mse: 0.3849 - val_loss: 0.4678 - val_mse: 0.4678\n",
      "Epoch 165/200\n",
      "1119/1119 [==============================] - 0s 162us/sample - loss: 0.3853 - mse: 0.3853 - val_loss: 0.4637 - val_mse: 0.4637\n",
      "Epoch 166/200\n",
      "1119/1119 [==============================] - 0s 206us/sample - loss: 0.3872 - mse: 0.3872 - val_loss: 0.4655 - val_mse: 0.4655\n",
      "Epoch 167/200\n",
      "1119/1119 [==============================] - 0s 108us/sample - loss: 0.3842 - mse: 0.3842 - val_loss: 0.4636 - val_mse: 0.4636\n",
      "Epoch 168/200\n",
      "1119/1119 [==============================] - 0s 155us/sample - loss: 0.3826 - mse: 0.3826 - val_loss: 0.4626 - val_mse: 0.4626\n",
      "Epoch 169/200\n",
      "1119/1119 [==============================] - 0s 147us/sample - loss: 0.3833 - mse: 0.3833 - val_loss: 0.4675 - val_mse: 0.4675\n",
      "Epoch 170/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.3842 - mse: 0.3842 - val_loss: 0.4621 - val_mse: 0.4621\n",
      "Epoch 171/200\n",
      "1119/1119 [==============================] - 0s 139us/sample - loss: 0.3825 - mse: 0.3825 - val_loss: 0.4576 - val_mse: 0.4576\n",
      "Epoch 172/200\n",
      "1119/1119 [==============================] - 0s 123us/sample - loss: 0.3823 - mse: 0.3823 - val_loss: 0.4585 - val_mse: 0.4585\n",
      "Epoch 173/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.3823 - mse: 0.3823 - val_loss: 0.4664 - val_mse: 0.4664\n",
      "Epoch 174/200\n",
      "1119/1119 [==============================] - 0s 126us/sample - loss: 0.3821 - mse: 0.3821 - val_loss: 0.4583 - val_mse: 0.4583\n",
      "Epoch 175/200\n",
      "1119/1119 [==============================] - 0s 143us/sample - loss: 0.3808 - mse: 0.3808 - val_loss: 0.4598 - val_mse: 0.4598\n",
      "Epoch 176/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 0.3810 - mse: 0.3810 - val_loss: 0.4571 - val_mse: 0.4571\n",
      "Epoch 177/200\n",
      "1119/1119 [==============================] - 0s 115us/sample - loss: 0.3800 - mse: 0.3800 - val_loss: 0.4590 - val_mse: 0.4590\n",
      "Epoch 178/200\n",
      "1119/1119 [==============================] - ETA: 0s - loss: 0.3885 - mse: 0.388 - 0s 117us/sample - loss: 0.3791 - mse: 0.3791 - val_loss: 0.4639 - val_mse: 0.4639\n",
      "Epoch 179/200\n",
      "1119/1119 [==============================] - 0s 155us/sample - loss: 0.3800 - mse: 0.3800 - val_loss: 0.4599 - val_mse: 0.4599\n",
      "Epoch 180/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.3800 - mse: 0.3800 - val_loss: 0.4586 - val_mse: 0.4586\n",
      "Epoch 181/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.3801 - mse: 0.3801 - val_loss: 0.4581 - val_mse: 0.4581\n",
      "Epoch 182/200\n",
      "1119/1119 [==============================] - 0s 106us/sample - loss: 0.3779 - mse: 0.3779 - val_loss: 0.4522 - val_mse: 0.4522\n",
      "Epoch 183/200\n",
      "1119/1119 [==============================] - 0s 144us/sample - loss: 0.3774 - mse: 0.3774 - val_loss: 0.4627 - val_mse: 0.4627\n",
      "Epoch 184/200\n",
      "1119/1119 [==============================] - 0s 118us/sample - loss: 0.3796 - mse: 0.3796 - val_loss: 0.4546 - val_mse: 0.4546\n",
      "Epoch 185/200\n",
      "1119/1119 [==============================] - 0s 121us/sample - loss: 0.3785 - mse: 0.3785 - val_loss: 0.4569 - val_mse: 0.4569\n",
      "Epoch 186/200\n",
      "1119/1119 [==============================] - 0s 120us/sample - loss: 0.3766 - mse: 0.3766 - val_loss: 0.4603 - val_mse: 0.4603\n",
      "Epoch 187/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 0.3773 - mse: 0.3773 - val_loss: 0.4573 - val_mse: 0.4573\n",
      "Epoch 188/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.3771 - mse: 0.3771 - val_loss: 0.4555 - val_mse: 0.4555\n",
      "Epoch 189/200\n",
      "1119/1119 [==============================] - 0s 103us/sample - loss: 0.3762 - mse: 0.3762 - val_loss: 0.4498 - val_mse: 0.4498\n",
      "Epoch 190/200\n",
      "1119/1119 [==============================] - 0s 158us/sample - loss: 0.3775 - mse: 0.3775 - val_loss: 0.4550 - val_mse: 0.4550\n",
      "Epoch 191/200\n",
      "1119/1119 [==============================] - 0s 195us/sample - loss: 0.3777 - mse: 0.3777 - val_loss: 0.4563 - val_mse: 0.4563\n",
      "Epoch 192/200\n",
      "1119/1119 [==============================] - 0s 162us/sample - loss: 0.3771 - mse: 0.3771 - val_loss: 0.4519 - val_mse: 0.4519\n",
      "Epoch 193/200\n",
      "1119/1119 [==============================] - 0s 102us/sample - loss: 0.3772 - mse: 0.3772 - val_loss: 0.4508 - val_mse: 0.4508\n",
      "Epoch 194/200\n",
      "1119/1119 [==============================] - 0s 137us/sample - loss: 0.3771 - mse: 0.3771 - val_loss: 0.4571 - val_mse: 0.4571\n",
      "Epoch 195/200\n",
      "1119/1119 [==============================] - 0s 105us/sample - loss: 0.3750 - mse: 0.3750 - val_loss: 0.4555 - val_mse: 0.4555\n",
      "Epoch 196/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 0.3758 - mse: 0.3758 - val_loss: 0.4501 - val_mse: 0.4501\n",
      "Epoch 197/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.3759 - mse: 0.3759 - val_loss: 0.4486 - val_mse: 0.4486\n",
      "Epoch 198/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.3767 - mse: 0.3767 - val_loss: 0.4489 - val_mse: 0.4489\n",
      "Epoch 199/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 0.3757 - mse: 0.3757 - val_loss: 0.4522 - val_mse: 0.4522\n",
      "Epoch 200/200\n",
      "1119/1119 [==============================] - 0s 121us/sample - loss: 0.3754 - mse: 0.3754 - val_loss: 0.4548 - val_mse: 0.4548\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Train the model\n",
    "model_1 = nn.fit(X, y, validation_split=0.3, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the train and test loss function\n",
    "plt.plot(model_1.history[\"loss\"])\n",
    "plt.title(\"loss_function - 1 hidden layer\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = 11\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 4\n",
    "\n",
    "nn = Sequential()\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1119 samples, validate on 480 samples\n",
      "Epoch 1/200\n",
      "1119/1119 [==============================] - 1s 1ms/sample - loss: 27.2966 - mse: 27.2966 - val_loss: 26.2462 - val_mse: 26.2462\n",
      "Epoch 2/200\n",
      "1119/1119 [==============================] - 0s 157us/sample - loss: 24.0012 - mse: 24.0012 - val_loss: 23.4674 - val_mse: 23.4674\n",
      "Epoch 3/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 19.8768 - mse: 19.8768 - val_loss: 20.0413 - val_mse: 20.0413\n",
      "Epoch 4/200\n",
      "1119/1119 [==============================] - 0s 273us/sample - loss: 15.2731 - mse: 15.2731 - val_loss: 15.9830 - val_mse: 15.9830\n",
      "Epoch 5/200\n",
      "1119/1119 [==============================] - 0s 233us/sample - loss: 10.8678 - mse: 10.8678 - val_loss: 11.8728 - val_mse: 11.8728\n",
      "Epoch 6/200\n",
      "1119/1119 [==============================] - 0s 154us/sample - loss: 7.4326 - mse: 7.4326 - val_loss: 8.2207 - val_mse: 8.2207\n",
      "Epoch 7/200\n",
      "1119/1119 [==============================] - 0s 150us/sample - loss: 5.0849 - mse: 5.0849 - val_loss: 5.5457 - val_mse: 5.5457\n",
      "Epoch 8/200\n",
      "1119/1119 [==============================] - 0s 145us/sample - loss: 3.6829 - mse: 3.6829 - val_loss: 4.0388 - val_mse: 4.0388\n",
      "Epoch 9/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 2.9085 - mse: 2.9085 - val_loss: 3.3173 - val_mse: 3.3173\n",
      "Epoch 10/200\n",
      "1119/1119 [==============================] - 0s 223us/sample - loss: 2.4745 - mse: 2.4745 - val_loss: 2.9114 - val_mse: 2.9114\n",
      "Epoch 11/200\n",
      "1119/1119 [==============================] - 0s 161us/sample - loss: 2.2003 - mse: 2.2003 - val_loss: 2.6298 - val_mse: 2.6298\n",
      "Epoch 12/200\n",
      "1119/1119 [==============================] - 0s 173us/sample - loss: 2.0113 - mse: 2.0113 - val_loss: 2.3975 - val_mse: 2.3975\n",
      "Epoch 13/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 1.8550 - mse: 1.8550 - val_loss: 2.2350 - val_mse: 2.2350\n",
      "Epoch 14/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 1.7372 - mse: 1.7372 - val_loss: 2.1127 - val_mse: 2.1127\n",
      "Epoch 15/200\n",
      "1119/1119 [==============================] - 0s 144us/sample - loss: 1.6410 - mse: 1.6410 - val_loss: 1.9793 - val_mse: 1.9793\n",
      "Epoch 16/200\n",
      "1119/1119 [==============================] - 0s 294us/sample - loss: 1.5580 - mse: 1.5580 - val_loss: 1.8923 - val_mse: 1.8923\n",
      "Epoch 17/200\n",
      "1119/1119 [==============================] - 0s 211us/sample - loss: 1.4834 - mse: 1.4834 - val_loss: 1.8137 - val_mse: 1.8137\n",
      "Epoch 18/200\n",
      "1119/1119 [==============================] - 0s 415us/sample - loss: 1.4210 - mse: 1.4210 - val_loss: 1.7421 - val_mse: 1.7421\n",
      "Epoch 19/200\n",
      "1119/1119 [==============================] - 0s 233us/sample - loss: 1.3645 - mse: 1.3645 - val_loss: 1.6841 - val_mse: 1.6841\n",
      "Epoch 20/200\n",
      "1119/1119 [==============================] - 1s 498us/sample - loss: 1.3143 - mse: 1.3143 - val_loss: 1.6167 - val_mse: 1.6167\n",
      "Epoch 21/200\n",
      "1119/1119 [==============================] - 0s 321us/sample - loss: 1.2661 - mse: 1.2661 - val_loss: 1.5781 - val_mse: 1.5781\n",
      "Epoch 22/200\n",
      "1119/1119 [==============================] - 0s 324us/sample - loss: 1.2225 - mse: 1.2225 - val_loss: 1.5218 - val_mse: 1.5218\n",
      "Epoch 23/200\n",
      "1119/1119 [==============================] - 0s 179us/sample - loss: 1.1820 - mse: 1.1820 - val_loss: 1.4748 - val_mse: 1.4748\n",
      "Epoch 24/200\n",
      "1119/1119 [==============================] - 0s 171us/sample - loss: 1.1452 - mse: 1.1452 - val_loss: 1.4336 - val_mse: 1.4336\n",
      "Epoch 25/200\n",
      "1119/1119 [==============================] - 1s 477us/sample - loss: 1.1120 - mse: 1.1120 - val_loss: 1.3975 - val_mse: 1.3975\n",
      "Epoch 26/200\n",
      "1119/1119 [==============================] - 0s 264us/sample - loss: 1.0769 - mse: 1.0769 - val_loss: 1.3599 - val_mse: 1.3599\n",
      "Epoch 27/200\n",
      "1119/1119 [==============================] - 0s 403us/sample - loss: 1.0449 - mse: 1.0449 - val_loss: 1.3309 - val_mse: 1.3309\n",
      "Epoch 28/200\n",
      "1119/1119 [==============================] - 0s 208us/sample - loss: 1.0156 - mse: 1.0156 - val_loss: 1.2838 - val_mse: 1.2838\n",
      "Epoch 29/200\n",
      "1119/1119 [==============================] - 0s 396us/sample - loss: 0.9854 - mse: 0.9854 - val_loss: 1.2604 - val_mse: 1.2604\n",
      "Epoch 30/200\n",
      "1119/1119 [==============================] - 0s 352us/sample - loss: 0.9592 - mse: 0.9592 - val_loss: 1.2301 - val_mse: 1.2301\n",
      "Epoch 31/200\n",
      "1119/1119 [==============================] - 0s 320us/sample - loss: 0.9323 - mse: 0.9323 - val_loss: 1.1951 - val_mse: 1.1951\n",
      "Epoch 32/200\n",
      "1119/1119 [==============================] - 0s 157us/sample - loss: 0.9051 - mse: 0.9051 - val_loss: 1.1629 - val_mse: 1.1629\n",
      "Epoch 33/200\n",
      "1119/1119 [==============================] - 0s 191us/sample - loss: 0.8831 - mse: 0.8831 - val_loss: 1.1299 - val_mse: 1.1299\n",
      "Epoch 34/200\n",
      "1119/1119 [==============================] - 0s 196us/sample - loss: 0.8579 - mse: 0.8579 - val_loss: 1.1088 - val_mse: 1.1088\n",
      "Epoch 35/200\n",
      "1119/1119 [==============================] - 0s 141us/sample - loss: 0.8377 - mse: 0.8377 - val_loss: 1.0794 - val_mse: 1.0794\n",
      "Epoch 36/200\n",
      "1119/1119 [==============================] - 0s 154us/sample - loss: 0.8183 - mse: 0.8183 - val_loss: 1.0535 - val_mse: 1.0535\n",
      "Epoch 37/200\n",
      "1119/1119 [==============================] - 0s 169us/sample - loss: 0.7995 - mse: 0.7995 - val_loss: 1.0354 - val_mse: 1.0354\n",
      "Epoch 38/200\n",
      "1119/1119 [==============================] - 0s 176us/sample - loss: 0.7786 - mse: 0.7786 - val_loss: 1.0046 - val_mse: 1.0046\n",
      "Epoch 39/200\n",
      "1119/1119 [==============================] - 0s 176us/sample - loss: 0.7615 - mse: 0.7615 - val_loss: 0.9904 - val_mse: 0.9904\n",
      "Epoch 40/200\n",
      "1119/1119 [==============================] - 0s 209us/sample - loss: 0.7442 - mse: 0.7442 - val_loss: 0.9609 - val_mse: 0.9609\n",
      "Epoch 41/200\n",
      "1119/1119 [==============================] - 0s 175us/sample - loss: 0.7280 - mse: 0.7280 - val_loss: 0.9392 - val_mse: 0.9392\n",
      "Epoch 42/200\n",
      "1119/1119 [==============================] - 0s 161us/sample - loss: 0.7135 - mse: 0.7135 - val_loss: 0.9235 - val_mse: 0.9235\n",
      "Epoch 43/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 0.6980 - mse: 0.6980 - val_loss: 0.9091 - val_mse: 0.9091\n",
      "Epoch 44/200\n",
      "1119/1119 [==============================] - 0s 147us/sample - loss: 0.6805 - mse: 0.6805 - val_loss: 0.8805 - val_mse: 0.8805\n",
      "Epoch 45/200\n",
      "1119/1119 [==============================] - 0s 172us/sample - loss: 0.6653 - mse: 0.6653 - val_loss: 0.8598 - val_mse: 0.8598\n",
      "Epoch 46/200\n",
      "1119/1119 [==============================] - 0s 171us/sample - loss: 0.6516 - mse: 0.6516 - val_loss: 0.8411 - val_mse: 0.8411\n",
      "Epoch 47/200\n",
      "1119/1119 [==============================] - 0s 161us/sample - loss: 0.6389 - mse: 0.6389 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 48/200\n",
      "1119/1119 [==============================] - 0s 132us/sample - loss: 0.6273 - mse: 0.6273 - val_loss: 0.8187 - val_mse: 0.8187\n",
      "Epoch 49/200\n",
      "1119/1119 [==============================] - 0s 171us/sample - loss: 0.6139 - mse: 0.6139 - val_loss: 0.8003 - val_mse: 0.8003\n",
      "Epoch 50/200\n",
      "1119/1119 [==============================] - 0s 152us/sample - loss: 0.6039 - mse: 0.6039 - val_loss: 0.7879 - val_mse: 0.7879\n",
      "Epoch 51/200\n",
      "1119/1119 [==============================] - 0s 171us/sample - loss: 0.5923 - mse: 0.5923 - val_loss: 0.7781 - val_mse: 0.7781\n",
      "Epoch 52/200\n",
      "1119/1119 [==============================] - 0s 162us/sample - loss: 0.5823 - mse: 0.5823 - val_loss: 0.7638 - val_mse: 0.7638\n",
      "Epoch 53/200\n",
      "1119/1119 [==============================] - 0s 194us/sample - loss: 0.5726 - mse: 0.5726 - val_loss: 0.7498 - val_mse: 0.7498\n",
      "Epoch 54/200\n",
      "1119/1119 [==============================] - 0s 222us/sample - loss: 0.5627 - mse: 0.5627 - val_loss: 0.7425 - val_mse: 0.7425\n",
      "Epoch 55/200\n",
      "1119/1119 [==============================] - 0s 113us/sample - loss: 0.5543 - mse: 0.5543 - val_loss: 0.7271 - val_mse: 0.7271\n",
      "Epoch 56/200\n",
      "1119/1119 [==============================] - 0s 145us/sample - loss: 0.5450 - mse: 0.5450 - val_loss: 0.7222 - val_mse: 0.7222\n",
      "Epoch 57/200\n",
      "1119/1119 [==============================] - 0s 149us/sample - loss: 0.5360 - mse: 0.5360 - val_loss: 0.7177 - val_mse: 0.7177\n",
      "Epoch 58/200\n",
      "1119/1119 [==============================] - 0s 131us/sample - loss: 0.5299 - mse: 0.5299 - val_loss: 0.7004 - val_mse: 0.7004\n",
      "Epoch 59/200\n",
      "1119/1119 [==============================] - 0s 150us/sample - loss: 0.5235 - mse: 0.5235 - val_loss: 0.6867 - val_mse: 0.6867\n",
      "Epoch 60/200\n",
      "1119/1119 [==============================] - 0s 176us/sample - loss: 0.5137 - mse: 0.5137 - val_loss: 0.6803 - val_mse: 0.6803\n",
      "Epoch 61/200\n",
      "1119/1119 [==============================] - 0s 149us/sample - loss: 0.5067 - mse: 0.5067 - val_loss: 0.6747 - val_mse: 0.6747\n",
      "Epoch 62/200\n",
      "1119/1119 [==============================] - 0s 147us/sample - loss: 0.5010 - mse: 0.5010 - val_loss: 0.6609 - val_mse: 0.6609\n",
      "Epoch 63/200\n",
      "1119/1119 [==============================] - 0s 178us/sample - loss: 0.4954 - mse: 0.4954 - val_loss: 0.6572 - val_mse: 0.6572\n",
      "Epoch 64/200\n",
      "1119/1119 [==============================] - 0s 179us/sample - loss: 0.4896 - mse: 0.4896 - val_loss: 0.6534 - val_mse: 0.6534\n",
      "Epoch 65/200\n",
      "1119/1119 [==============================] - 0s 166us/sample - loss: 0.4839 - mse: 0.4839 - val_loss: 0.6378 - val_mse: 0.6378\n",
      "Epoch 66/200\n",
      "1119/1119 [==============================] - 0s 109us/sample - loss: 0.4787 - mse: 0.4787 - val_loss: 0.6389 - val_mse: 0.6389\n",
      "Epoch 67/200\n",
      "1119/1119 [==============================] - 0s 163us/sample - loss: 0.4765 - mse: 0.4765 - val_loss: 0.6283 - val_mse: 0.6283\n",
      "Epoch 68/200\n",
      "1119/1119 [==============================] - 0s 134us/sample - loss: 0.4693 - mse: 0.4693 - val_loss: 0.6185 - val_mse: 0.6185\n",
      "Epoch 69/200\n",
      "1119/1119 [==============================] - 0s 163us/sample - loss: 0.4669 - mse: 0.4669 - val_loss: 0.6176 - val_mse: 0.6176\n",
      "Epoch 70/200\n",
      "1119/1119 [==============================] - 0s 173us/sample - loss: 0.4636 - mse: 0.4636 - val_loss: 0.6177 - val_mse: 0.6177\n",
      "Epoch 71/200\n",
      "1119/1119 [==============================] - 0s 140us/sample - loss: 0.4587 - mse: 0.4587 - val_loss: 0.6005 - val_mse: 0.6005\n",
      "Epoch 72/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.4557 - mse: 0.4557 - val_loss: 0.6080 - val_mse: 0.6080\n",
      "Epoch 73/200\n",
      "1119/1119 [==============================] - 0s 122us/sample - loss: 0.4502 - mse: 0.4502 - val_loss: 0.5906 - val_mse: 0.5906\n",
      "Epoch 74/200\n",
      "1119/1119 [==============================] - 0s 164us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.5980 - val_mse: 0.5980\n",
      "Epoch 75/200\n",
      "1119/1119 [==============================] - 0s 184us/sample - loss: 0.4454 - mse: 0.4454 - val_loss: 0.5859 - val_mse: 0.5859\n",
      "Epoch 76/200\n",
      "1119/1119 [==============================] - 0s 152us/sample - loss: 0.4420 - mse: 0.4420 - val_loss: 0.5869 - val_mse: 0.5869\n",
      "Epoch 77/200\n",
      "1119/1119 [==============================] - 0s 191us/sample - loss: 0.4392 - mse: 0.4392 - val_loss: 0.5797 - val_mse: 0.5797\n",
      "Epoch 78/200\n",
      "1119/1119 [==============================] - 0s 169us/sample - loss: 0.4377 - mse: 0.4377 - val_loss: 0.5731 - val_mse: 0.5731\n",
      "Epoch 79/200\n",
      "1119/1119 [==============================] - 0s 145us/sample - loss: 0.4350 - mse: 0.4350 - val_loss: 0.5784 - val_mse: 0.5784\n",
      "Epoch 80/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.4338 - mse: 0.4338 - val_loss: 0.5748 - val_mse: 0.5748\n",
      "Epoch 81/200\n",
      "1119/1119 [==============================] - 0s 95us/sample - loss: 0.4320 - mse: 0.4320 - val_loss: 0.5579 - val_mse: 0.5579\n",
      "Epoch 82/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 0.4286 - mse: 0.4286 - val_loss: 0.5672 - val_mse: 0.5672\n",
      "Epoch 83/200\n",
      "1119/1119 [==============================] - 0s 166us/sample - loss: 0.4265 - mse: 0.4265 - val_loss: 0.5619 - val_mse: 0.5619\n",
      "Epoch 84/200\n",
      "1119/1119 [==============================] - 0s 157us/sample - loss: 0.4279 - mse: 0.4279 - val_loss: 0.5717 - val_mse: 0.5717\n",
      "Epoch 85/200\n",
      "1119/1119 [==============================] - 0s 149us/sample - loss: 0.4243 - mse: 0.4243 - val_loss: 0.5507 - val_mse: 0.5507\n",
      "Epoch 86/200\n",
      "1119/1119 [==============================] - 0s 140us/sample - loss: 0.4234 - mse: 0.4234 - val_loss: 0.5453 - val_mse: 0.5453\n",
      "Epoch 87/200\n",
      "1119/1119 [==============================] - 0s 153us/sample - loss: 0.4201 - mse: 0.4201 - val_loss: 0.5489 - val_mse: 0.5489\n",
      "Epoch 88/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 0.4190 - mse: 0.4190 - val_loss: 0.5521 - val_mse: 0.5521\n",
      "Epoch 89/200\n",
      "1119/1119 [==============================] - 0s 154us/sample - loss: 0.4172 - mse: 0.4172 - val_loss: 0.5442 - val_mse: 0.5442\n",
      "Epoch 90/200\n",
      "1119/1119 [==============================] - 0s 150us/sample - loss: 0.4181 - mse: 0.4181 - val_loss: 0.5454 - val_mse: 0.5454\n",
      "Epoch 91/200\n",
      "1119/1119 [==============================] - 0s 156us/sample - loss: 0.4179 - mse: 0.4179 - val_loss: 0.5452 - val_mse: 0.5452\n",
      "Epoch 92/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.4172 - mse: 0.4172 - val_loss: 0.5399 - val_mse: 0.5399\n",
      "Epoch 93/200\n",
      "1119/1119 [==============================] - 0s 160us/sample - loss: 0.4145 - mse: 0.4145 - val_loss: 0.5355 - val_mse: 0.5355\n",
      "Epoch 94/200\n",
      "1119/1119 [==============================] - 0s 144us/sample - loss: 0.4149 - mse: 0.4149 - val_loss: 0.5436 - val_mse: 0.5436\n",
      "Epoch 95/200\n",
      "1119/1119 [==============================] - 0s 113us/sample - loss: 0.4138 - mse: 0.4138 - val_loss: 0.5459 - val_mse: 0.5459\n",
      "Epoch 96/200\n",
      "1119/1119 [==============================] - 0s 166us/sample - loss: 0.4141 - mse: 0.4141 - val_loss: 0.5274 - val_mse: 0.5274\n",
      "Epoch 97/200\n",
      "1119/1119 [==============================] - 0s 150us/sample - loss: 0.4121 - mse: 0.4121 - val_loss: 0.5320 - val_mse: 0.5320\n",
      "Epoch 98/200\n",
      "1119/1119 [==============================] - 0s 238us/sample - loss: 0.4128 - mse: 0.4128 - val_loss: 0.5474 - val_mse: 0.5474\n",
      "Epoch 99/200\n",
      "1119/1119 [==============================] - 0s 185us/sample - loss: 0.4111 - mse: 0.4111 - val_loss: 0.5287 - val_mse: 0.5287\n",
      "Epoch 100/200\n",
      "1119/1119 [==============================] - 0s 156us/sample - loss: 0.4115 - mse: 0.4115 - val_loss: 0.5381 - val_mse: 0.5381\n",
      "Epoch 101/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 0.4112 - mse: 0.4112 - val_loss: 0.5384 - val_mse: 0.5384\n",
      "Epoch 102/200\n",
      "1119/1119 [==============================] - 0s 139us/sample - loss: 0.4104 - mse: 0.4104 - val_loss: 0.5425 - val_mse: 0.5425\n",
      "Epoch 103/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 0.4079 - mse: 0.4079 - val_loss: 0.5345 - val_mse: 0.5345\n",
      "Epoch 104/200\n",
      "1119/1119 [==============================] - 0s 128us/sample - loss: 0.4103 - mse: 0.4103 - val_loss: 0.5280 - val_mse: 0.5280\n",
      "Epoch 105/200\n",
      "1119/1119 [==============================] - 0s 162us/sample - loss: 0.4061 - mse: 0.4061 - val_loss: 0.5328 - val_mse: 0.5328\n",
      "Epoch 106/200\n",
      "1119/1119 [==============================] - 0s 159us/sample - loss: 0.4082 - mse: 0.4082 - val_loss: 0.5328 - val_mse: 0.5328\n",
      "Epoch 107/200\n",
      "1119/1119 [==============================] - 0s 156us/sample - loss: 0.4061 - mse: 0.4061 - val_loss: 0.5275 - val_mse: 0.5275\n",
      "Epoch 108/200\n",
      "1119/1119 [==============================] - 0s 181us/sample - loss: 0.4041 - mse: 0.4041 - val_loss: 0.5366 - val_mse: 0.5366\n",
      "Epoch 109/200\n",
      "1119/1119 [==============================] - 0s 160us/sample - loss: 0.4059 - mse: 0.4059 - val_loss: 0.5319 - val_mse: 0.5319\n",
      "Epoch 110/200\n",
      "1119/1119 [==============================] - 0s 128us/sample - loss: 0.4047 - mse: 0.4047 - val_loss: 0.5239 - val_mse: 0.5239\n",
      "Epoch 111/200\n",
      "1119/1119 [==============================] - 0s 155us/sample - loss: 0.4049 - mse: 0.4049 - val_loss: 0.5435 - val_mse: 0.5435\n",
      "Epoch 112/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 0.4036 - mse: 0.4036 - val_loss: 0.5299 - val_mse: 0.5299\n",
      "Epoch 113/200\n",
      "1119/1119 [==============================] - 0s 118us/sample - loss: 0.4040 - mse: 0.4040 - val_loss: 0.5223 - val_mse: 0.5223\n",
      "Epoch 114/200\n",
      "1119/1119 [==============================] - 0s 114us/sample - loss: 0.4056 - mse: 0.4056 - val_loss: 0.5267 - val_mse: 0.5267\n",
      "Epoch 115/200\n",
      "1119/1119 [==============================] - 0s 157us/sample - loss: 0.4037 - mse: 0.4037 - val_loss: 0.5158 - val_mse: 0.5158\n",
      "Epoch 116/200\n",
      "1119/1119 [==============================] - 0s 123us/sample - loss: 0.4034 - mse: 0.4034 - val_loss: 0.5577 - val_mse: 0.5577\n",
      "Epoch 117/200\n",
      "1119/1119 [==============================] - 0s 153us/sample - loss: 0.4044 - mse: 0.4044 - val_loss: 0.5233 - val_mse: 0.5233\n",
      "Epoch 118/200\n",
      "1119/1119 [==============================] - 0s 121us/sample - loss: 0.4034 - mse: 0.4034 - val_loss: 0.5237 - val_mse: 0.5237\n",
      "Epoch 119/200\n",
      "1119/1119 [==============================] - 0s 122us/sample - loss: 0.4003 - mse: 0.4003 - val_loss: 0.5245 - val_mse: 0.5245\n",
      "Epoch 120/200\n",
      "1119/1119 [==============================] - 0s 177us/sample - loss: 0.4002 - mse: 0.4002 - val_loss: 0.5366 - val_mse: 0.5366\n",
      "Epoch 121/200\n",
      "1119/1119 [==============================] - 0s 235us/sample - loss: 0.4006 - mse: 0.4006 - val_loss: 0.5207 - val_mse: 0.5207\n",
      "Epoch 122/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3996 - mse: 0.3996 - val_loss: 0.5186 - val_mse: 0.5186\n",
      "Epoch 123/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 0.4007 - mse: 0.4007 - val_loss: 0.5280 - val_mse: 0.5280\n",
      "Epoch 124/200\n",
      "1119/1119 [==============================] - 0s 126us/sample - loss: 0.4020 - mse: 0.4020 - val_loss: 0.5244 - val_mse: 0.5244\n",
      "Epoch 125/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 0.3990 - mse: 0.3990 - val_loss: 0.5216 - val_mse: 0.5216\n",
      "Epoch 126/200\n",
      "1119/1119 [==============================] - 0s 162us/sample - loss: 0.3996 - mse: 0.3996 - val_loss: 0.5305 - val_mse: 0.5305\n",
      "Epoch 127/200\n",
      "1119/1119 [==============================] - 0s 178us/sample - loss: 0.3983 - mse: 0.3983 - val_loss: 0.5266 - val_mse: 0.5266\n",
      "Epoch 128/200\n",
      "1119/1119 [==============================] - 0s 134us/sample - loss: 0.3996 - mse: 0.3996 - val_loss: 0.5164 - val_mse: 0.5164\n",
      "Epoch 129/200\n",
      "1119/1119 [==============================] - 0s 115us/sample - loss: 0.3978 - mse: 0.3978 - val_loss: 0.5259 - val_mse: 0.5259\n",
      "Epoch 130/200\n",
      "1119/1119 [==============================] - 0s 169us/sample - loss: 0.3979 - mse: 0.3979 - val_loss: 0.5158 - val_mse: 0.5158\n",
      "Epoch 131/200\n",
      "1119/1119 [==============================] - 0s 139us/sample - loss: 0.3966 - mse: 0.3966 - val_loss: 0.5226 - val_mse: 0.5226\n",
      "Epoch 132/200\n",
      "1119/1119 [==============================] - 0s 132us/sample - loss: 0.3993 - mse: 0.3993 - val_loss: 0.5164 - val_mse: 0.5164\n",
      "Epoch 133/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 0.3972 - mse: 0.3972 - val_loss: 0.5234 - val_mse: 0.5234\n",
      "Epoch 134/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 0.3975 - mse: 0.3975 - val_loss: 0.5140 - val_mse: 0.5140\n",
      "Epoch 135/200\n",
      "1119/1119 [==============================] - 0s 116us/sample - loss: 0.3969 - mse: 0.3969 - val_loss: 0.5197 - val_mse: 0.5197\n",
      "Epoch 136/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 0.3967 - mse: 0.3967 - val_loss: 0.5092 - val_mse: 0.5092\n",
      "Epoch 137/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.3983 - mse: 0.3983 - val_loss: 0.5184 - val_mse: 0.5184\n",
      "Epoch 138/200\n",
      "1119/1119 [==============================] - 0s 105us/sample - loss: 0.3963 - mse: 0.3963 - val_loss: 0.5114 - val_mse: 0.5114\n",
      "Epoch 139/200\n",
      "1119/1119 [==============================] - 0s 154us/sample - loss: 0.3962 - mse: 0.3962 - val_loss: 0.5251 - val_mse: 0.5251\n",
      "Epoch 140/200\n",
      "1119/1119 [==============================] - 0s 126us/sample - loss: 0.3963 - mse: 0.3963 - val_loss: 0.5335 - val_mse: 0.5335\n",
      "Epoch 141/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.3931 - mse: 0.3931 - val_loss: 0.5149 - val_mse: 0.5149\n",
      "Epoch 142/200\n",
      "1119/1119 [==============================] - 0s 149us/sample - loss: 0.3948 - mse: 0.3948 - val_loss: 0.5284 - val_mse: 0.5284\n",
      "Epoch 143/200\n",
      "1119/1119 [==============================] - 0s 141us/sample - loss: 0.3947 - mse: 0.3947 - val_loss: 0.5260 - val_mse: 0.5260\n",
      "Epoch 144/200\n",
      "1119/1119 [==============================] - 0s 185us/sample - loss: 0.3946 - mse: 0.3946 - val_loss: 0.5088 - val_mse: 0.5088\n",
      "Epoch 145/200\n",
      "1119/1119 [==============================] - 0s 160us/sample - loss: 0.3936 - mse: 0.3936 - val_loss: 0.5142 - val_mse: 0.5142\n",
      "Epoch 146/200\n",
      "1119/1119 [==============================] - 0s 156us/sample - loss: 0.3933 - mse: 0.3933 - val_loss: 0.5516 - val_mse: 0.5516\n",
      "Epoch 147/200\n",
      "1119/1119 [==============================] - 0s 148us/sample - loss: 0.3927 - mse: 0.3927 - val_loss: 0.5110 - val_mse: 0.5110\n",
      "Epoch 148/200\n",
      "1119/1119 [==============================] - 0s 178us/sample - loss: 0.3917 - mse: 0.3917 - val_loss: 0.5256 - val_mse: 0.5256\n",
      "Epoch 149/200\n",
      "1119/1119 [==============================] - 0s 117us/sample - loss: 0.3930 - mse: 0.3930 - val_loss: 0.5186 - val_mse: 0.5186\n",
      "Epoch 150/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3957 - mse: 0.3957 - val_loss: 0.5276 - val_mse: 0.5276\n",
      "Epoch 151/200\n",
      "1119/1119 [==============================] - 0s 131us/sample - loss: 0.3942 - mse: 0.3942 - val_loss: 0.5079 - val_mse: 0.5079\n",
      "Epoch 152/200\n",
      "1119/1119 [==============================] - 0s 122us/sample - loss: 0.3931 - mse: 0.3931 - val_loss: 0.5005 - val_mse: 0.5005\n",
      "Epoch 153/200\n",
      "1119/1119 [==============================] - 0s 145us/sample - loss: 0.3922 - mse: 0.3922 - val_loss: 0.5180 - val_mse: 0.5180\n",
      "Epoch 154/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 0.3913 - mse: 0.3913 - val_loss: 0.5253 - val_mse: 0.5253\n",
      "Epoch 155/200\n",
      "1119/1119 [==============================] - 0s 142us/sample - loss: 0.3919 - mse: 0.3919 - val_loss: 0.5134 - val_mse: 0.5134\n",
      "Epoch 156/200\n",
      "1119/1119 [==============================] - 0s 135us/sample - loss: 0.3926 - mse: 0.3926 - val_loss: 0.5180 - val_mse: 0.5180\n",
      "Epoch 157/200\n",
      "1119/1119 [==============================] - 0s 141us/sample - loss: 0.3903 - mse: 0.3903 - val_loss: 0.5272 - val_mse: 0.5272\n",
      "Epoch 158/200\n",
      "1119/1119 [==============================] - 0s 123us/sample - loss: 0.3911 - mse: 0.3911 - val_loss: 0.4994 - val_mse: 0.4994\n",
      "Epoch 159/200\n",
      "1119/1119 [==============================] - 0s 130us/sample - loss: 0.3933 - mse: 0.3933 - val_loss: 0.5168 - val_mse: 0.5168\n",
      "Epoch 160/200\n",
      "1119/1119 [==============================] - 0s 159us/sample - loss: 0.3904 - mse: 0.3904 - val_loss: 0.5097 - val_mse: 0.5097\n",
      "Epoch 161/200\n",
      "1119/1119 [==============================] - 0s 118us/sample - loss: 0.3905 - mse: 0.3905 - val_loss: 0.5240 - val_mse: 0.5240\n",
      "Epoch 162/200\n",
      "1119/1119 [==============================] - 0s 151us/sample - loss: 0.3922 - mse: 0.3922 - val_loss: 0.5136 - val_mse: 0.5136\n",
      "Epoch 163/200\n",
      "1119/1119 [==============================] - 0s 136us/sample - loss: 0.3918 - mse: 0.3918 - val_loss: 0.5275 - val_mse: 0.5275\n",
      "Epoch 164/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3917 - mse: 0.3917 - val_loss: 0.5277 - val_mse: 0.5277\n",
      "Epoch 165/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 0.3917 - mse: 0.3917 - val_loss: 0.5115 - val_mse: 0.5115\n",
      "Epoch 166/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.3882 - mse: 0.3882 - val_loss: 0.5292 - val_mse: 0.5292\n",
      "Epoch 167/200\n",
      "1119/1119 [==============================] - 0s 145us/sample - loss: 0.3918 - mse: 0.3918 - val_loss: 0.5418 - val_mse: 0.5418\n",
      "Epoch 168/200\n",
      "1119/1119 [==============================] - 0s 139us/sample - loss: 0.3898 - mse: 0.3898 - val_loss: 0.5142 - val_mse: 0.5142\n",
      "Epoch 169/200\n",
      "1119/1119 [==============================] - 0s 133us/sample - loss: 0.3907 - mse: 0.3907 - val_loss: 0.4984 - val_mse: 0.4984\n",
      "Epoch 170/200\n",
      "1119/1119 [==============================] - 0s 166us/sample - loss: 0.3903 - mse: 0.3903 - val_loss: 0.4990 - val_mse: 0.4990\n",
      "Epoch 171/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.3897 - mse: 0.3897 - val_loss: 0.5022 - val_mse: 0.5022\n",
      "Epoch 172/200\n",
      "1119/1119 [==============================] - 0s 108us/sample - loss: 0.3912 - mse: 0.3912 - val_loss: 0.5033 - val_mse: 0.5033\n",
      "Epoch 173/200\n",
      "1119/1119 [==============================] - 0s 124us/sample - loss: 0.3886 - mse: 0.3886 - val_loss: 0.5076 - val_mse: 0.5076\n",
      "Epoch 174/200\n",
      "1119/1119 [==============================] - 0s 141us/sample - loss: 0.3942 - mse: 0.3942 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 175/200\n",
      "1119/1119 [==============================] - 0s 119us/sample - loss: 0.3921 - mse: 0.3921 - val_loss: 0.5168 - val_mse: 0.5168\n",
      "Epoch 176/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3878 - mse: 0.3878 - val_loss: 0.5382 - val_mse: 0.5382\n",
      "Epoch 177/200\n",
      "1119/1119 [==============================] - 0s 172us/sample - loss: 0.3884 - mse: 0.3884 - val_loss: 0.5198 - val_mse: 0.5198\n",
      "Epoch 178/200\n",
      "1119/1119 [==============================] - 0s 109us/sample - loss: 0.3873 - mse: 0.3873 - val_loss: 0.5072 - val_mse: 0.5072\n",
      "Epoch 179/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3900 - mse: 0.3900 - val_loss: 0.5102 - val_mse: 0.5102\n",
      "Epoch 180/200\n",
      "1119/1119 [==============================] - 0s 158us/sample - loss: 0.3899 - mse: 0.3899 - val_loss: 0.5084 - val_mse: 0.5084\n",
      "Epoch 181/200\n",
      "1119/1119 [==============================] - 0s 159us/sample - loss: 0.3866 - mse: 0.3866 - val_loss: 0.5233 - val_mse: 0.5233\n",
      "Epoch 182/200\n",
      "1119/1119 [==============================] - 0s 120us/sample - loss: 0.3883 - mse: 0.3883 - val_loss: 0.5291 - val_mse: 0.5291\n",
      "Epoch 183/200\n",
      "1119/1119 [==============================] - 0s 137us/sample - loss: 0.3888 - mse: 0.3888 - val_loss: 0.5129 - val_mse: 0.5129\n",
      "Epoch 184/200\n",
      "1119/1119 [==============================] - 0s 128us/sample - loss: 0.3863 - mse: 0.3863 - val_loss: 0.5159 - val_mse: 0.5159\n",
      "Epoch 185/200\n",
      "1119/1119 [==============================] - 0s 142us/sample - loss: 0.3872 - mse: 0.3872 - val_loss: 0.5095 - val_mse: 0.5095\n",
      "Epoch 186/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.3866 - mse: 0.3866 - val_loss: 0.5133 - val_mse: 0.5133\n",
      "Epoch 187/200\n",
      "1119/1119 [==============================] - 0s 115us/sample - loss: 0.3900 - mse: 0.3900 - val_loss: 0.5030 - val_mse: 0.5030\n",
      "Epoch 188/200\n",
      "1119/1119 [==============================] - 0s 139us/sample - loss: 0.3877 - mse: 0.3877 - val_loss: 0.5414 - val_mse: 0.5414\n",
      "Epoch 189/200\n",
      "1119/1119 [==============================] - 0s 127us/sample - loss: 0.3859 - mse: 0.3859 - val_loss: 0.5077 - val_mse: 0.5077\n",
      "Epoch 190/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.3881 - mse: 0.3881 - val_loss: 0.5130 - val_mse: 0.5130\n",
      "Epoch 191/200\n",
      "1119/1119 [==============================] - 0s 125us/sample - loss: 0.3847 - mse: 0.3847 - val_loss: 0.5148 - val_mse: 0.5148\n",
      "Epoch 192/200\n",
      "1119/1119 [==============================] - 0s 152us/sample - loss: 0.3886 - mse: 0.3886 - val_loss: 0.5003 - val_mse: 0.5003\n",
      "Epoch 193/200\n",
      "1119/1119 [==============================] - 0s 175us/sample - loss: 0.3835 - mse: 0.3835 - val_loss: 0.5199 - val_mse: 0.5199\n",
      "Epoch 194/200\n",
      "1119/1119 [==============================] - 0s 140us/sample - loss: 0.3835 - mse: 0.3835 - val_loss: 0.5060 - val_mse: 0.5060\n",
      "Epoch 195/200\n",
      "1119/1119 [==============================] - 0s 180us/sample - loss: 0.3861 - mse: 0.3861 - val_loss: 0.5342 - val_mse: 0.5342\n",
      "Epoch 196/200\n",
      "1119/1119 [==============================] - 0s 128us/sample - loss: 0.3848 - mse: 0.3848 - val_loss: 0.5188 - val_mse: 0.5188\n",
      "Epoch 197/200\n",
      "1119/1119 [==============================] - 0s 129us/sample - loss: 0.3844 - mse: 0.3844 - val_loss: 0.5091 - val_mse: 0.5091\n",
      "Epoch 198/200\n",
      "1119/1119 [==============================] - 0s 126us/sample - loss: 0.3858 - mse: 0.3858 - val_loss: 0.5198 - val_mse: 0.5198\n",
      "Epoch 199/200\n",
      "1119/1119 [==============================] - 0s 131us/sample - loss: 0.3873 - mse: 0.3873 - val_loss: 0.5284 - val_mse: 0.5284\n",
      "Epoch 200/200\n",
      "1119/1119 [==============================] - 0s 121us/sample - loss: 0.3848 - mse: 0.3848 - val_loss: 0.5289 - val_mse: 0.5289\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_2 = nn.fit(X, y, validation_split=0.3, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_1.history[\"loss\"])\n",
    "plt.plot(model_2.history[\"loss\"])\n",
    "plt.title(\"loss_function - Training\")\n",
    "plt.legend([\"1 hidden layer\", \"2 hidden layers\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for deep net\n",
    "plt.plot(model_2.history[\"loss\"])\n",
    "plt.plot(model_2.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - 2 hidden layers\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38475560681216947\n",
      "0.5289051632086436\n"
     ]
    }
   ],
   "source": [
    "print(model_2.history[\"loss\"][-1])\n",
    "print(model_2.history[\"val_loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
